{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fahrudeen/GraphRAG/blob/master/notebooks/graphrag_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "project_overview"
      },
      "source": [
        "# GraphRAG Supply Chain Management System\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "This notebook implements a **Graph-based Retrieval Augmented Generation (GraphRAG)** system for supply chain management using Neo4j graph database and Groq's LLM API.\n",
        "\n",
        "### Key Features\n",
        "- **Knowledge Graph Construction**: Build comprehensive supply chain relationships\n",
        "- **Intelligent Query Processing**: Natural language to Cypher query translation\n",
        "- **Context-Aware Responses**: LLM-powered answers using graph context\n",
        "- **Multi-Entity Relationships**: Cars, Features, Parts, and Suppliers\n",
        "\n",
        "### Architecture\n",
        "```\n",
        "User Query → LLM Query Generator → Neo4j Graph → Context Retrieval → LLM Response\n",
        "```\n",
        "\n",
        "### Prerequisites\n",
        "- Neo4j AuraDB instance or local Neo4j installation\n",
        "- Groq API access\n",
        "- Supply chain CSV data files\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_instructions"
      },
      "source": [
        "##  Setup and Configuration\n",
        "\n",
        "### Environment Variables\n",
        "\n",
        "**Important**: Before running this notebook, set up your environment variables:\n",
        "\n",
        "```\n",
        "# Create a .env file with:\n",
        "NEO4J_URI=your_neo4j_uri_here\n",
        "NEO4J_PASSWORD=****\n",
        "GROQ_API_KEY=****\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_dependencies"
      },
      "outputs": [],
      "source": [
        "# Install required dependencies\n",
        "!pip install neo4j groq pandas python-dotenv -q\n",
        "\n",
        "print(\" Dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_and_config"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from neo4j import GraphDatabase\n",
        "from groq import Groq\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Configuration with environment variables\n",
        "NEO4J_URI = os.getenv('NEO4J_URI', 'bolt://localhost:7687')\n",
        "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME', 'neo4j')\n",
        "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
        "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
        "\n",
        "# Validate configuration\n",
        "if not all([NEO4J_PASSWORD, GROQ_API_KEY]):\n",
        "    raise ValueError(\"Missing required environment variables. Please check your .env file.\")\n",
        "\n",
        "print(\"Configuration loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db_connection_header"
      },
      "source": [
        "## Database Connection Setup\n",
        "\n",
        "Establishing secure connection to Neo4j database with proper error handling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "database_connection"
      },
      "outputs": [],
      "source": [
        "def create_database_connection():\n",
        "    \"\"\"Create and test Neo4j database connection.\"\"\"\n",
        "    try:\n",
        "        driver = GraphDatabase.driver(\n",
        "            NEO4J_URI,\n",
        "            auth=(NEO4J_USERNAME, NEO4J_PASSWORD)\n",
        "        )\n",
        "        return driver\n",
        "    except Exception as e:\n",
        "        print(f\"Database connection failed: {e}\")\n",
        "        raise\n",
        "\n",
        "def test_connection(driver):\n",
        "    \"\"\"Test database connectivity.\"\"\"\n",
        "    try:\n",
        "        with driver.session() as session:\n",
        "            result = session.run(\"RETURN 'Neo4j Connected!' AS message\")\n",
        "            message = result.single()[\"message\"]\n",
        "            print(f\"{message}\")\n",
        "            return True\n",
        "    except Exception as e:\n",
        "        print(f\"Connection test failed: {e}\")\n",
        "        return False\n",
        "\n",
        "# Initialize database connection\n",
        "driver = create_database_connection()\n",
        "test_connection(driver)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_loading_header"
      },
      "source": [
        "## Data Loading and Preparation\n",
        "\n",
        "Loading supply chain data from CSV files. Update the file paths according to your data location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_loading"
      },
      "outputs": [],
      "source": [
        "def load_supply_chain_data():\n",
        "    \"\"\"Load all supply chain CSV files.\"\"\"\n",
        "\n",
        "    # Update these paths according to your data location\n",
        "    data_files = {\n",
        "        'car_models': 'data/nodes_car_model.csv',\n",
        "        'features': 'data/nodes_feature.csv',\n",
        "        'parts': 'data/nodes_part.csv',\n",
        "        'suppliers': 'data/nodes_supplier.csv',\n",
        "        'with_feature': 'data/with_feature.csv',\n",
        "        'is_composed_of': 'data/is_composed_of.csv',\n",
        "        'is_supplied_by': 'data/is_supplied_by.csv'\n",
        "    }\n",
        "\n",
        "    dataframes = {}\n",
        "\n",
        "    for name, filepath in data_files.items():\n",
        "        try:\n",
        "            df = pd.read_csv(filepath)\n",
        "            dataframes[name] = df\n",
        "            print(f\"Loaded {name}: {len(df)} records\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"File not found: {filepath}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {name}: {e}\")\n",
        "\n",
        "    return dataframes\n",
        "\n",
        "# Load data\n",
        "data = load_supply_chain_data()\n",
        "\n",
        "# Display data structure\n",
        "print(\"\\nData Structure Overview:\")\n",
        "for name, df in data.items():\n",
        "    print(f\"{name}: {list(df.columns)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "graph_construction_header"
      },
      "source": [
        "## Knowledge Graph Construction\n",
        "\n",
        "Building the supply chain knowledge graph with nodes and relationships."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "graph_construction"
      },
      "outputs": [],
      "source": [
        "class GraphBuilder:\n",
        "    \"\"\"Handles knowledge graph construction operations.\"\"\"\n",
        "\n",
        "    def __init__(self, driver):\n",
        "        self.driver = driver\n",
        "\n",
        "    def create_car_models(self, df_car):\n",
        "        \"\"\"Insert car model nodes into the graph.\"\"\"\n",
        "        def insert_car_model(tx, row):\n",
        "            query = \"\"\"\n",
        "            MERGE (c:CarModel {vertex_id: $vertex_id})\n",
        "            SET c.name = $name,\n",
        "                c.number = $number,\n",
        "                c.year = toInteger($year),\n",
        "                c.type = $type,\n",
        "                c.engine_type = $engine_type,\n",
        "                c.size = $size,\n",
        "                c.seats = toInteger($seats)\n",
        "            \"\"\"\n",
        "            tx.run(query, **row)\n",
        "\n",
        "        with self.driver.session() as session:\n",
        "            for _, row in df_car.iterrows():\n",
        "                session.execute_write(insert_car_model, row.to_dict())\n",
        "\n",
        "        print(f\"Created {len(df_car)} car model nodes\")\n",
        "\n",
        "    def create_features(self, df_feature):\n",
        "        \"\"\"Insert feature nodes into the graph.\"\"\"\n",
        "        def insert_feature(tx, row):\n",
        "            query = \"\"\"\n",
        "            MERGE (f:Feature {vertex_id: $vertex_id})\n",
        "            SET f.name = $name,\n",
        "                f.number = $number,\n",
        "                f.type = $type,\n",
        "                f.state = $state\n",
        "            \"\"\"\n",
        "            tx.run(query, **row)\n",
        "\n",
        "        with self.driver.session() as session:\n",
        "            for _, row in df_feature.iterrows():\n",
        "                session.execute_write(insert_feature, row.to_dict())\n",
        "\n",
        "        print(f\"Created {len(df_feature)} feature nodes\")\n",
        "\n",
        "    def create_parts(self, df_part):\n",
        "        \"\"\"Insert part nodes into the graph.\"\"\"\n",
        "        def insert_part(tx, row):\n",
        "            query = \"\"\"\n",
        "            MERGE (p:Part {vertex_id: $vertex_id})\n",
        "            SET p.name = $name,\n",
        "                p.number = $number,\n",
        "                p.price = toFloat($price),\n",
        "                p.date = date($date)\n",
        "            \"\"\"\n",
        "            tx.run(query, **row)\n",
        "\n",
        "        with self.driver.session() as session:\n",
        "            for _, row in df_part.iterrows():\n",
        "                session.execute_write(insert_part, row.to_dict())\n",
        "\n",
        "        print(f\"Created {len(df_part)} part nodes\")\n",
        "\n",
        "    def create_suppliers(self, df_supplier):\n",
        "        \"\"\"Insert supplier nodes into the graph.\"\"\"\n",
        "        def insert_supplier(tx, row):\n",
        "            query = \"\"\"\n",
        "            MERGE (s:Supplier {vertex_id: $vertex_id})\n",
        "            SET s.name = $name,\n",
        "                s.address = $address,\n",
        "                s.contact = $contact,\n",
        "                s.phone_number = $phone_number\n",
        "            \"\"\"\n",
        "            tx.run(query, **row)\n",
        "\n",
        "        with self.driver.session() as session:\n",
        "            for _, row in df_supplier.iterrows():\n",
        "                session.execute_write(insert_supplier, row.to_dict())\n",
        "\n",
        "        print(f\"Created {len(df_supplier)} supplier nodes\")\n",
        "\n",
        "# Initialize graph builder\n",
        "if 'car_models' in data:\n",
        "    graph_builder = GraphBuilder(driver)\n",
        "\n",
        "    # Create nodes\n",
        "    graph_builder.create_car_models(data['car_models'])\n",
        "    graph_builder.create_features(data['features'])\n",
        "    graph_builder.create_parts(data['parts'])\n",
        "    graph_builder.create_suppliers(data['suppliers'])\n",
        "else:\n",
        "    print(\"Skipping graph construction - data not loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "relationships_header"
      },
      "source": [
        "## Relationship Creation\n",
        "\n",
        "Creating relationships between nodes to form the complete knowledge graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_relationships"
      },
      "outputs": [],
      "source": [
        "class RelationshipBuilder:\n",
        "    \"\"\"Handles relationship creation in the knowledge graph.\"\"\"\n",
        "\n",
        "    def __init__(self, driver):\n",
        "        self.driver = driver\n",
        "\n",
        "    def create_with_feature_relationships(self, df_with_feature):\n",
        "        \"\"\"Create WITH_FEATURE relationships between cars and features.\"\"\"\n",
        "        def insert_relationship(tx, row):\n",
        "            query = \"\"\"\n",
        "            MATCH (c:CarModel {vertex_id: $src_node_id})\n",
        "            MATCH (f:Feature {vertex_id: $dst_node_id})\n",
        "            MERGE (c)-[:WITH_FEATURE {version: $version}]->(f)\n",
        "            \"\"\"\n",
        "            tx.run(query, **row)\n",
        "\n",
        "        with self.driver.session() as session:\n",
        "            for _, row in df_with_feature.iterrows():\n",
        "                session.execute_write(insert_relationship, row.to_dict())\n",
        "\n",
        "        print(f\"Created {len(df_with_feature)} WITH_FEATURE relationships\")\n",
        "\n",
        "    def create_composed_of_relationships(self, df_is_composed_of):\n",
        "        \"\"\"Create IS_COMPOSED_OF relationships between features and parts.\"\"\"\n",
        "        def insert_relationship(tx, row):\n",
        "            query = \"\"\"\n",
        "            MATCH (f:Feature {vertex_id: $src_id})\n",
        "            MATCH (p:Part {vertex_id: $dst_id})\n",
        "            MERGE (f)-[:IS_COMPOSED_OF {version: $version}]->(p)\n",
        "            \"\"\"\n",
        "            tx.run(query, **row)\n",
        "\n",
        "        with self.driver.session() as session:\n",
        "            for _, row in df_is_composed_of.iterrows():\n",
        "                session.execute_write(insert_relationship, row.to_dict())\n",
        "\n",
        "        print(f\"Created {len(df_is_composed_of)} IS_COMPOSED_OF relationships\")\n",
        "\n",
        "    def create_supplied_by_relationships(self, df_is_supplied_by):\n",
        "        \"\"\"Create IS_SUPPLIED_BY relationships between parts and suppliers.\"\"\"\n",
        "        def insert_relationship(tx, row):\n",
        "            query = \"\"\"\n",
        "            MATCH (p:Part {vertex_id: $src_id})\n",
        "            MATCH (s:Supplier {vertex_id: $dst_id})\n",
        "            MERGE (p)-[:IS_SUPPLIED_BY {version: $version}]->(s)\n",
        "            \"\"\"\n",
        "            tx.run(query, **row)\n",
        "\n",
        "        with self.driver.session() as session:\n",
        "            for _, row in df_is_supplied_by.iterrows():\n",
        "                session.execute_write(insert_relationship, row.to_dict())\n",
        "\n",
        "        print(f\"Created {len(df_is_supplied_by)} IS_SUPPLIED_BY relationships\")\n",
        "\n",
        "# Create relationships\n",
        "if all(key in data for key in ['with_feature', 'is_composed_of', 'is_supplied_by']):\n",
        "    rel_builder = RelationshipBuilder(driver)\n",
        "\n",
        "    rel_builder.create_with_feature_relationships(data['with_feature'])\n",
        "    rel_builder.create_composed_of_relationships(data['is_composed_of'])\n",
        "    rel_builder.create_supplied_by_relationships(data['is_supplied_by'])\n",
        "\n",
        "    print(\"\\nKnowledge graph construction completed!\")\n",
        "else:\n",
        "    print(\"Skipping relationship creation - data not loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llm_integration_header"
      },
      "source": [
        "## LLM Integration and Query Processing\n",
        "\n",
        "Setting up Groq LLM client and implementing intelligent query processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llm_integration"
      },
      "outputs": [],
      "source": [
        "class QueryProcessor:\n",
        "    \"\"\"Handles LLM-powered query processing and Cypher generation.\"\"\"\n",
        "\n",
        "    def __init__(self, groq_api_key, driver):\n",
        "        self.client = Groq(api_key=groq_api_key)\n",
        "        self.driver = driver\n",
        "        self.system_prompt = self._create_system_prompt()\n",
        "\n",
        "    def _create_system_prompt(self):\n",
        "        \"\"\"Create system prompt for Cypher query generation.\"\"\"\n",
        "        return \"\"\"\n",
        "        You are a Cypher query generator for a supply chain graph in Neo4j.\n",
        "\n",
        "        The graph includes:\n",
        "\n",
        "        Nodes:\n",
        "        - CarModel: vertex_id, name, number, year, type, engine_type, size, seats\n",
        "        - Feature: vertex_id, name, number, type, state\n",
        "        - Part: vertex_id, name, number, price, date\n",
        "        - Supplier: vertex_id, name, address, contact, phone_number\n",
        "\n",
        "        Relationships:\n",
        "        - (CarModel)-[:WITH_FEATURE {version}]->(Feature)\n",
        "        - (Feature)-[:IS_COMPOSED_OF {version}]->(Part)\n",
        "        - (Part)-[:IS_SUPPLIED_BY {version}]->(Supplier)\n",
        "\n",
        "        Rules:\n",
        "        - Use MATCH and RETURN only\n",
        "        - Filter by number, name, or vertex_id\n",
        "        - Return just the Cypher query without additional context\n",
        "\n",
        "        Examples:\n",
        "        Q: Features of C1000\n",
        "        A: MATCH (c:CarModel {number: \"C1000\"})-[:WITH_FEATURE]->(f:Feature) RETURN f.name;\n",
        "\n",
        "        Q: Tell me about Car A\n",
        "        A: MATCH (c:CarModel {name: \"Model A\"}) RETURN c;\n",
        "\n",
        "        Q: Parts used in feature f_13\n",
        "        A: MATCH (:Feature {vertex_id: \"f_13\"})-[:IS_COMPOSED_OF]->(p:Part) RETURN p.name;\n",
        "        \"\"\"\n",
        "\n",
        "    def generate_cypher(self, user_query):\n",
        "        \"\"\"Generate Cypher query from natural language.\"\"\"\n",
        "        try:\n",
        "            prompt = f\"{self.system_prompt}\\n\\nThe query from user is: {user_query}\"\n",
        "\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=\"llama-3.3-70b-versatile\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "            )\n",
        "\n",
        "            return response.choices[0].message.content.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating Cypher: {e}\")\n",
        "            return None\n",
        "\n",
        "    def execute_cypher(self, cypher_query):\n",
        "        \"\"\"Execute Cypher query against Neo4j database.\"\"\"\n",
        "        try:\n",
        "            with self.driver.session() as session:\n",
        "                result = session.run(cypher_query)\n",
        "                records = [record.data() for record in result]\n",
        "                return records\n",
        "        except Exception as e:\n",
        "            print(f\"Error executing query: {e}\")\n",
        "            return None\n",
        "\n",
        "    def generate_response(self, user_query, retrieved_data):\n",
        "        \"\"\"Generate natural language response using retrieved data.\"\"\"\n",
        "        try:\n",
        "            system_message = (\n",
        "                \"You are a GraphRAG Client communication AI for XYZ Automobile services. \"\n",
        "                \"You will be provided with retrieved data from the graph database and the user's query. \"\n",
        "                \"Provide helpful, accurate responses based on the data.\"\n",
        "            )\n",
        "\n",
        "            user_message = f\"Retrieved context: {retrieved_data}\\nQuery: {user_query}\"\n",
        "\n",
        "            response = self.client.chat.completions.create(\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": system_message},\n",
        "                    {\"role\": \"user\", \"content\": user_message}\n",
        "                ],\n",
        "                model=\"llama-3.3-70b-versatile\"\n",
        "            )\n",
        "\n",
        "            return response.choices[0].message.content\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating response: {e}\")\n",
        "            return \"Sorry, I encountered an error processing your request.\"\n",
        "\n",
        "# Initialize query processor\n",
        "query_processor = QueryProcessor(GROQ_API_KEY, driver)\n",
        "print(\"Query processor initialized successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "query_interface_header"
      },
      "source": [
        "## Interactive Query Interface\n",
        "\n",
        "Interactive system for querying the supply chain knowledge graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "query_interface"
      },
      "outputs": [],
      "source": [
        "def run_graphrag_query(user_query):\n",
        "    \"\"\"Execute complete GraphRAG pipeline for a user query.\"\"\"\n",
        "    print(f\"Processing query: {user_query}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Step 1: Generate Cypher query\n",
        "    cypher_query = query_processor.generate_cypher(user_query)\n",
        "    if not cypher_query:\n",
        "        return \"Failed to generate query\"\n",
        "\n",
        "    print(f\"Generated Cypher:\\n{cypher_query}\\n\")\n",
        "\n",
        "    # Step 2: Execute query\n",
        "    retrieved_data = query_processor.execute_cypher(cypher_query)\n",
        "    if retrieved_data is None:\n",
        "        return \"Failed to execute query\"\n",
        "\n",
        "    print(f\"Retrieved {len(retrieved_data)} records\\n\")\n",
        "\n",
        "    # Step 3: Generate natural language response\n",
        "    response = query_processor.generate_response(user_query, retrieved_data)\n",
        "\n",
        "    print(\"AI Response:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(response)\n",
        "\n",
        "    return response\n",
        "\n",
        "# Example usage\n",
        "print(\"GraphRAG system ready for queries!\")\n",
        "print(\"\\nExample queries:\")\n",
        "print(\"- 'Features of Model A'\")\n",
        "print(\"- 'Compare Model A and Model C'\")\n",
        "print(\"- 'Parts used in sunroof feature'\")\n",
        "print(\"- 'Suppliers for brake parts'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "interactive_query"
      },
      "outputs": [],
      "source": [
        "# Interactive query cell - Run this to ask questions\n",
        "user_query = input(\"🎤 Ask your supply chain question: \")\n",
        "run_graphrag_query(user_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utilities_header"
      },
      "source": [
        "## Utility Functions\n",
        "\n",
        "Additional utility functions for database management."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utilities"
      },
      "outputs": [],
      "source": [
        "def get_graph_statistics():\n",
        "    \"\"\"Get overview statistics of the knowledge graph.\"\"\"\n",
        "    queries = {\n",
        "        'Car Models': 'MATCH (c:CarModel) RETURN count(c) as count',\n",
        "        'Features': 'MATCH (f:Feature) RETURN count(f) as count',\n",
        "        'Parts': 'MATCH (p:Part) RETURN count(p) as count',\n",
        "        'Suppliers': 'MATCH (s:Supplier) RETURN count(s) as count',\n",
        "        'Total Relationships': 'MATCH ()-[r]-() RETURN count(r) as count'\n",
        "    }\n",
        "\n",
        "    print(\"Knowledge Graph Statistics:\")\n",
        "    print(\"=\" * 35)\n",
        "\n",
        "    with driver.session() as session:\n",
        "        for name, query in queries.items():\n",
        "            result = session.run(query)\n",
        "            count = result.single()['count']\n",
        "            print(f\"{name:<20}: {count:>10,}\")\n",
        "\n",
        "def cleanup_database():\n",
        "    \"\"\"Clean up database (use with caution!).\"\"\"\n",
        "    confirmation = input(\"⚠️  Are you sure you want to delete all data? (type 'YES' to confirm): \")\n",
        "\n",
        "    if confirmation == 'YES':\n",
        "        with driver.session() as session:\n",
        "            session.run(\"MATCH (n) DETACH DELETE n\")\n",
        "        print(\"Database cleaned successfully!\")\n",
        "    else:\n",
        "        print(\"Operation cancelled.\")\n",
        "\n",
        "def close_connection():\n",
        "    \"\"\"Close database connection.\"\"\"\n",
        "    if driver:\n",
        "        driver.close()\n",
        "        print(\"Database connection closed.\")\n",
        "\n",
        "# Display current graph statistics\n",
        "get_graph_statistics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "This GraphRAG implementation demonstrates:\n",
        "\n",
        "### Achievements\n",
        "- **Knowledge Graph**: Successfully built comprehensive supply chain relationships\n",
        "- **Natural Language Processing**: Intelligent query translation to Cypher\n",
        "- **Context-Aware Responses**: LLM-powered answers using graph context\n",
        "- **Scalable Architecture**: Modular design for easy extension\n",
        "\n",
        "### Next Steps\n",
        "- Add graph visualization capabilities\n",
        "- Implement query optimization\n",
        "- Add more complex relationship types\n",
        "- Integrate with web interface\n",
        "\n",
        "### Resources\n",
        "- [Neo4j Documentation](https://neo4j.com/docs/)\n",
        "- [Groq API Documentation](https://groq.com/)\n",
        "- [Graph Database Best Practices](https://neo4j.com/developer/)\n",
        "\n",
        "---\n",
        "\n",
        "**Remember**: Always close the database connection when finished:\n",
        "```\n",
        "close_connection()\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}